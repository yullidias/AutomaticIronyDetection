{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "from svm import *\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolds(nPartitions, base):\n",
    "    listIndex = [i for i in base['id'].tolist()]\n",
    "    nelements = math.ceil(len(listIndex) / nPartitions)\n",
    "\n",
    "    count = 0\n",
    "    folds = {}\n",
    "    for start in range(0, len(listIndex), nelements):\n",
    "        folds[count] = listIndex[start : start+nelements]\n",
    "        count += 1\n",
    "    assert(nPartitions == len(folds))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPartitionsForTrainingValidationAndTest(nPartitions):\n",
    "    folds = []\n",
    "    for n in range(nPartitions):\n",
    "        partition = {}\n",
    "        partition['training'] = [] \n",
    "        nPartitionsTraining = nPartitions - 2 #considerando 1 particao para treino e 1 para teste\n",
    "        for i in range(nPartitionsTraining): \n",
    "            partition['training'] += [(n + i) % nPartitions]\n",
    "        partition['validation'] = (n + nPartitionsTraining) % nPartitions\n",
    "        partition['test'] = (n + nPartitionsTraining + 1) % nPartitions\n",
    "        folds += [partition]\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDefinedFolds(foldsPath, folds, foldsWithDefinedPartitions):\n",
    "    if os.path.exists(foldsPath):\n",
    "        shutil.rmtree(foldsPath)\n",
    "        \n",
    "    os.makedirs(foldsPath)\n",
    "        \n",
    "    count = 0        \n",
    "    for fold in foldsWithDefinedPartitions:\n",
    "        actualDir = foldsPath + str(count) + \"/\"\n",
    "        if not os.path.exists(actualDir):\n",
    "            os.makedirs(actualDir)\n",
    "        training = []\n",
    "        for n in fold['training']:\n",
    "            training += folds[n]\n",
    "\n",
    "        with open(actualDir + TRAINING_IDS_FILE, 'w') as f:\n",
    "            f.write(json.dumps(training, indent=2))\n",
    "        with open(actualDir + VALIDATION_IDS_FILE, 'w') as f:\n",
    "            f.write(json.dumps(folds[fold['validation']], indent=2))\n",
    "        with open(actualDir + TEST_IDS_FILE, 'w') as f:\n",
    "            f.write(json.dumps(folds[fold['test']], indent=2))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFolds(nPartitions, base, foldsPathToWrite):\n",
    "    foldsDict = getFolds(nPartitions, base)\n",
    "    foldsWithDefinedPartitions = getPartitionsForTrainingValidationAndTest(nPartitions)\n",
    "    writeDefinedFolds(foldsPathToWrite, foldsDict, foldsWithDefinedPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(foldsPath, fold, partitionName, base):\n",
    "    with open(foldsPath + str(fold) + '/' +  partitionName + '.json', 'r') as f:\n",
    "        idlist = json.loads(f.read())\n",
    "        dataset = base.loc[base['id'].isin(idlist)]\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulario(baseToGenerateVocabularyPath, BOWAndNgram, fileToWriteVectorizer):\n",
    "    vocabularyDF = pd.read_excel(baseToGenerateVocabularyPath, index_col=0)\n",
    "    vocabularyDF['text'] = vocabularyDF['text'].values.astype('U')\n",
    "    if BOWAndNgram:\n",
    "        vectorizer = CountVectorizer(lowercase=False, ngram_range=(1,3))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(lowercase=False)    \n",
    "    vectorizer.fit_transform(vocabularyDF[\"text\"])\n",
    "    print(\"N features: \" + str(len(vectorizer.vocabulary_)) + (\" [BOW+Ngram]\" if BOWAndNgram else \" [BOW]\"))\n",
    "    writeObjectInFile(fileToWriteVectorizer, vectorizer)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmClassifier(root, filename, kernel, c, bestScore, trainingFeatures, trainingDF, testFeatures, testDF, writeObject):\n",
    "    print(\"C: \" + str(c))\n",
    "    log = {}\n",
    "    log[\"Parametros\"] = {\"kernel\" : kernel, \"c\" : str(c) }\n",
    "    \n",
    "    classifier = svm.SVC(kernel=kernel, C=c)\n",
    "    classifier.fit(trainingFeatures, trainingDF['rotulo'])\n",
    "    predict = classifier.predict(testFeatures)     \n",
    "    savePrediction(testDF, predict, root)\n",
    "    log[\"classifier\"] = classifier.get_params(True)\n",
    "\n",
    "    if writeObject:\n",
    "        writeObjectInFile(root + PYTHON_OBJECT_FILE, classifier)    \n",
    "    \n",
    "    report = classification_report(testDF['rotulo'], predict, output_dict=True)\n",
    "    log[\"report\"] = report\n",
    "    \n",
    "    selectedScore = report['macro avg']['precision']\n",
    "    if(bestScore != None and selectedScore > bestScore['score']):\n",
    "        bestScore['C'] = c\n",
    "        bestScore['score'] = selectedScore   \n",
    "        \n",
    "    log[\"score\"] = selectedScore\n",
    "    log[\"bestScore\"] = bestScore\n",
    "    \n",
    "    confusionMatrix = confusion_matrix(testDF['rotulo'], predict)\n",
    "    log[\"confusionMatrix\"] = str(confusionMatrix)\n",
    "\n",
    "    with open(root + filename, 'a') as filelog:\n",
    "        filelog.write(json.dumps(log, indent=1))\n",
    "        filelog.close()\n",
    "    return bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationFold(kernel, Clist, foldsPath, fold, vectorizerVocabulary, base):    \n",
    "    print(\"-- Fold: \" + str(fold))\n",
    "    trainingDF = getDataset(foldsPath, fold, 'training', base)\n",
    "    trainingFeatures = getFeatures(vectorizerVocabulary, trainingDF)\n",
    "    validationDF = getDataset(foldsPath, fold, 'validation', base)\n",
    "    validationFeatures = getFeatures(vectorizerVocabulary, validationDF)\n",
    "    \n",
    "    bestScore = {'C' : -1, 'score' : -1}   \n",
    "    print(\"Validation ...\")\n",
    "    for c in Clist:\n",
    "        bestScore = svmClassifier(foldsPath + str(fold) + \"/\", VALIDATION_FILE,\n",
    "                        kernel, c, bestScore, trainingFeatures, trainingDF, validationFeatures, validationDF, False)\n",
    "    \n",
    "    print(\"Test ...\")\n",
    "    testDF = getDataset(foldsPath, fold, 'test', base)\n",
    "    testFeatures = getFeatures(vectorizerVocabulary, testDF)\n",
    "    svmClassifier(foldsPath + str(fold) + \"/\", TEST_LOG_FILE,\n",
    "           kernel, bestScore['C'], None,\n",
    "            trainingFeatures, trainingDF, testFeatures, testDF, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationKFold(k, root, dataBasePath, baseToGenerateVocabularyPath, BOWAndNgramIfTrueAndBOWIfFalse):\n",
    "    print(\"Obtendo a base ...\")\n",
    "    base = getBaseDF(dataBasePath)\n",
    "    print(\"obtendo o vocabulario ...\")\n",
    "    foldsPath = root + str(k) + 'folds/'\n",
    "    print(\"Gerando os folds ...\")\n",
    "    generateFolds(k, base, foldsPath) \n",
    "    vocabularyVectorizer = getVocabulario(baseToGenerateVocabularyPath,\n",
    "                                          BOWAndNgramIfTrueAndBOWIfFalse, foldsPath + VECTORIZER_OBJECT_FILE)  \n",
    "    Clist = [2**x for x in range(-5, 17, 2)]    \n",
    "    for fold in range(k):\n",
    "        crossValidationFold('linear', Clist, foldsPath, fold, vocabularyVectorizer, base)\n",
    "    print(\"--- END ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**Example execution**\n",
    "\n",
    "ABOSOLUTE_PATH = '../'\n",
    "\n",
    "crossValidationKFold(5, ABOSOLUTE_PATH + 'SVM/BOWNgram/', ['class1.xlsx', 'class2.xlsx'], 'preprocess.xlsx', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
