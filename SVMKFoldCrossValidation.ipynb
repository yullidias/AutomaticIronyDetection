{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBase(ironicDataPath, naoIronicDataPath):\n",
    "    ironicosDF = pd.read_excel(ironicDataPath, index_col=0)\n",
    "    naorotuladoDF = pd.read_excel(naoIronicDataPath, index_col=0)    \n",
    "    base = ironicosDF.append(naorotuladoDF, ignore_index=True)\n",
    "    base['text'] = base['text'].values.astype('U')\n",
    "    base['rotulo'] = base['rotulo'].values.astype(int)\n",
    "    base = base.sample(frac=1, replace=True, random_state=17) #use the same random_state for reproducibility\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulario(baseToGenerateVocabularyPath, BOWAndNgram):\n",
    "    vocabularyDF = pd.read_excel(baseToGenerateVocabularyPath, index_col=0)\n",
    "    vocabularyDF['text'] = vocabularyDF['text'].values.astype('U')\n",
    "    vocabularyDF['rotulo'] = vocabularyDF['rotulo'].values.astype(int)\n",
    "    if BOWAndNgram:\n",
    "        vectorizer = CountVectorizer(lowercase=False, ngram_range=(1,3))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(lowercase=False)\n",
    "    vectorizer.fit_transform(vocabularyDF[\"text\"])\n",
    "    print(\"N features: \" + str(len(vectorizer.vocabulary_)) + \" [BOW+Ngram]\" if BOWAndNgram else \" [BOW]\")\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolds(nPartitions, base):\n",
    "    listIndex = [i for i in base['id'].tolist()]\n",
    "    nelements = math.ceil(len(listIndex) / nPartitions)\n",
    "\n",
    "    count = 0\n",
    "    folds = {}\n",
    "    for start in range(0, len(listIndex), nelements):\n",
    "        folds[count] = listIndex[start : start+nelements]\n",
    "        count += 1\n",
    "    assert(nPartitions == len(folds))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPartitionsForTrainingValidationAndTest(nPartitions):\n",
    "    folds = []\n",
    "    for n in range(nPartitions):\n",
    "        partition = {}\n",
    "        partition['training'] = [] \n",
    "        nPartitionsTraining = nPartitions - 2 #considerando 1 particao para treino e 1 para teste\n",
    "        for i in range(nPartitionsTraining): \n",
    "            partition['training'] += [(n + i) % nPartitions]\n",
    "        partition['validation'] = (n + nPartitionsTraining) % nPartitions\n",
    "        partition['test'] = (n + nPartitionsTraining + 1) % nPartitions\n",
    "        folds += [partition]\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDefinedFolds(foldsPath, folds, foldsWithDefinedPartitions):\n",
    "    if os.path.exists(foldsPath):\n",
    "        shutil.rmtree(foldsPath)\n",
    "        \n",
    "    os.makedirs(foldsPath)\n",
    "        \n",
    "    count = 0        \n",
    "    for fold in foldsWithDefinedPartitions:\n",
    "        actualDir = foldsPath + str(count) + \"/\"\n",
    "        if not os.path.exists(actualDir):\n",
    "            os.makedirs(actualDir)\n",
    "        training = []\n",
    "        for n in fold['training']:\n",
    "            training += folds[n]\n",
    "\n",
    "        with open(actualDir + 'training.json', 'w') as f:\n",
    "            f.write(json.dumps(training, indent=2))\n",
    "        with open(actualDir + 'validation.json', 'w') as f:\n",
    "            f.write(json.dumps(folds[fold['validation']], indent=2))\n",
    "        with open(actualDir + 'test.json', 'w') as f:\n",
    "            f.write(json.dumps(folds[fold['test']], indent=2))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFolds(nPartitions, base, foldsPathToWrite):\n",
    "    foldsDict = getFolds(nPartitions, base)\n",
    "    foldsWithDefinedPartitions = getPartitionsForTrainingValidationAndTest(nPartitions)\n",
    "    writeDefinedFolds(foldsPathToWrite, foldsDict, foldsWithDefinedPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(foldsPath, fold, partitionName, base):\n",
    "    with open(foldsPath + str(fold) + '/' +  partitionName + '.json', 'r') as f:\n",
    "        idlist = json.loads(f.read())\n",
    "        dataset = base.loc[base['id'].isin(idlist)]\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesAndClass(vectorizerVocabulary, dataset):    \n",
    "    features = vectorizerVocabulary.transform(dataset['text'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmClassifier(filelog, kernel, c, bestScore, trainingFeatures, trainingDF, testFeatures, testDF):\n",
    "    print(\"C: \" + str(c))\n",
    "    f = open(filelog, 'a')\n",
    "    f.write(\"kernel: \" + kernel + \" c: \" + str(c) + \"\\n\")\n",
    "    \n",
    "    classifier = svm.SVC(kernel=kernel, C=c)\n",
    "    classifier.fit(trainingFeatures, trainingDF['rotulo'])\n",
    "    predict = classifier.predict(testFeatures)\n",
    "\n",
    "    f.write(json.dumps(classifier.get_params(True), indent=1) + \"\\n\")\n",
    "    \n",
    "    report = classification_report(testDF['rotulo'], predict, output_dict=True)\n",
    "    f.write(json.dumps(report, indent=1) + \"\\n\")\n",
    "    \n",
    "    selectedScore = report['micro avg']['precision']\n",
    "    if(bestScore != None and selectedScore > bestScore['score']):\n",
    "        bestScore['C'] = c\n",
    "        bestScore['score'] = selectedScore   \n",
    "        \n",
    "    f.write(json.dumps({ 'score': selectedScore, 'bestSocore': bestScore}, indent=1) + \"\\n\")\n",
    "    f.write(\"confusion Matrix\" + \"\\n\")\n",
    "    confusionMatrix = confusion_matrix(testDF['rotulo'], predict)\n",
    "    f.write(str(confusionMatrix) + \"\\n\")\n",
    "    f.close()\n",
    "    return bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationFold(kernel, Clist, foldsPath, fold, vectorizerVocabulary, base):    \n",
    "    print(\"-- Fold: \" + str(fold))\n",
    "    trainingDF = getDataset(foldsPath, fold, 'training', base)\n",
    "    trainingFeatures = getFeaturesAndClass(vectorizerVocabulary, trainingDF)\n",
    "    validationDF = getDataset(foldsPath, fold, 'validation', base)\n",
    "    validationFeatures = getFeaturesAndClass(vectorizerVocabulary, validationDF)\n",
    "    \n",
    "    bestScore = {'C' : -1, 'score' : -1}   \n",
    "    print(\"Validation ...\")\n",
    "    for c in Clist:\n",
    "        bestScore = svmClassifier(foldsPath + str(fold) + '/logValidation.txt',\n",
    "                        kernel, c, bestScore, trainingFeatures, trainingDF, validationFeatures, validationDF)\n",
    "    \n",
    "    print(\"Test ...\")\n",
    "    testDF = getDataset(foldsPath, fold, 'test', base)\n",
    "    testFeatures = getFeaturesAndClass(vectorizerVocabulary, testDF)\n",
    "    svmClassifier(foldsPath + str(fold) + '/logTest.txt',\n",
    "           kernel, bestScore['C'], None,\n",
    "            trainingFeatures, trainingDF, testFeatures, testDF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationKFold(k, root, ironicDataPath, naoIronicDataPath, baseToGenerateVocabularyPath, BOWAndNgramIfTrueAndBOWIfFalse):\n",
    "    print(\"Obtendo a base ...\")\n",
    "    base = getBase(ironicDataPath,\n",
    "                   naoIronicDataPath)\n",
    "    print(\"obtendo o vocabulario ...\")\n",
    "    vocabularyVectorizer = getVocabulario(baseToGenerateVocabularyPath,\n",
    "                                          BOWAndNgramIfTrueAndBOWIfFalse)\n",
    "    foldsPath = root + str(k) + 'folds/'\n",
    "    print(\"gerando os folds ...\")\n",
    "    generateFolds(k, base, foldsPath) \n",
    "    Clist = [2**x for x in range(-5, 17, 2)]\n",
    "    for fold in range(k):\n",
    "        crossValidationFold('linear', Clist, foldsPath, fold, vocabularyVectorizer, base)\n",
    "    print(\"--- END ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base rotuladada + coletada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crossValidationKFold(5,\n",
    "                     'SVM/',\n",
    "                     'data/ironic.xlsx',\n",
    "                     'data/notIronic.xlsx',\n",
    "                     'data/preprocess.xlsx',\n",
    "                     True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
